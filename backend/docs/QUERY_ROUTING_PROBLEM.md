# 查询路由问题说明（供调研用）

本文档说明当前 Backend 在「用户提问 → 检索与回答」这条链路上遇到的问题，包括背景、现状做法和由此带来的问题，便于其他人做调研与方案设计。

---

## 1. 问题的背景

### 1.1 系统在解决什么问题

**Narrative Mirror** 把微信聊天历史变成「有证据支撑的叙事」。用户用自然语言提问，系统需要：

- 从该对话的**大量 TopicNode（对话节点）**里找出和问题相关的部分；
- 基于这些节点里的真实消息，生成**有引用、可追溯**的回答。

对话可能很长（数月甚至数年），节点数量可能达到几十到上百个，所以**不可能也不必要**对每个问题都扫遍所有节点；需要在「召回范围」和「成本/延迟」之间做权衡。

### 1.2 用户问题的多样性

用户的问题大致可以分为两类（后续方案可以再细分）：

- **针对整段长对话的「叙事/过程」类问题**  
  例如：「我们是怎么一步步分手的」「这段关系是怎么演变的」「入职后工作进展如何」。  
  特点：关心**长时间线上的变化、阶段、转折**，需要覆盖对话的多个时段（早期、中期、后期），否则叙事会缺段、结论片面。

- **针对具体事实的「查证」类问题**  
  例如：「我们去年 7 月份吃了什么」「第一次吵架是什么时候」「2023 年 6 月约了哪家餐厅」。  
  特点：有较明确的**时间或事件锚点**，答案往往落在少数几段对话里；只要找到那几段并摘出事实即可，**不需要**对整条时间线做均匀覆盖。

当前实现里，**不论哪种问题，都走同一套「重」流程**：多路检索 + 充足性评估 + 多轮探索 + 多阶段叙事生成。对第二类问题来说，这套流程在成本和体验上都不理想，因此需要把「问题类型」和「解决方式」区分开，让调研和后续设计有明确目标。

---

## 2. 我们目前是怎么解决的

下面按「单次请求」的视角，说明从收到用户问题到返回结果，我们**实际在做的事**。代码入口与逻辑以当前 Backend 为准（如 `run_query`、LangGraph workflow、Q1–Q5）。

### 2.1 统一入口与意图解析（Q1）

- 所有问题先进 **Q1 `parse_intent()`**：用 CoT LLM 把用户问题解析成结构化意图 `QueryIntent`。
- 意图里包含：
  - **query_type**：`arc_narrative`（过程/演变）、`time_point`（某时间点发生了什么）、`event_retrieval`（某具体事件）；
  - **focus_dimensions**：关注的信号维度（如情感、冲突、沉默等）；
  - **time_range**：若问题里带时间，则解析出时间范围（如 `"2023-06"`）。

目前**没有**根据问题类型做「轻量路径 vs 重量路径」的分流，只根据 query_type 在**同一套流程内部**调整检索策略（见下）。

### 2.2 检索阶段：多路召回 + 对「叙事」类拉满时间线

在 **Retriever**（Agent 模式）或 **Q2+Q3**（One-shot 模式）中，我们对**每一个问题**都会做：

1. **lookup_anchors**  
   按意图里的 `focus_dimensions` 和 `time_range` 查异常锚点（AnomalyAnchor），得到一批「有信号异常」的节点。

2. **search_semantic**  
   用 1～3 个由问题生成的检索 query，对 ChromaDB 做语义检索，每个 query 取 top_k（如 10）个节点。

3. **get_thread_neighbors**  
   对每个锚点节点，沿语义线程（Layer 2）扩展邻居，把同一语义线索上的节点都拉进来。

4. **对 arc_narrative 额外做 get_all_nodes_overview**  
   若 Q1 判为 `arc_narrative`，再调 `get_all_nodes_overview(limit=60)`，把整条对话时间线上的节点（最多 60 个）都纳入候选，以保证「叙事弧」在时间上尽量覆盖整段对话。

也就是说：  
- **叙事类**：我们刻意把「尽可能多的对话节点」纳入候选（锚点 + 语义 + 线程 + 全量概览），相当于在**为整段长对话做宽覆盖**。  
- **事实类**：虽然理论上 time_point / event_retrieval 不会触发 get_all_nodes_overview，但仍会走**锚点 + 多 query 语义检索 + 线程扩展**，并且紧接着进入下面的「充足性评估 + 探索」循环。

### 2.3 充足性评估（Grader）与多轮探索（Explorer）

- **Grader** 根据当前已收集的节点数量、时间分布、与问题的匹配度，判断「是否足以回答用户问题」。
- 对 **arc_narrative** 有硬性规则：若收集到的节点在时间轴上的 Q1/Q2/Q3/Q4 四个象限里**任一象限为 0**，则判为不足，并建议 Explorer 做 **time_search** 补全缺失时段。
- 若判为不足，则进入 **Explorer**：按建议执行 `list_nodes_by_time`、或再次 `search_semantic`、或 `get_thread_neighbors`，把新节点合并进候选集，然后**再次进入 Grader**。
- 如此可循环多轮（如最多 3 轮），直到 Grader 认为足够或达到最大轮数，才进入生成阶段。

因此，**即使用户只是问「去年 7 月我们吃了什么」**，当前实现也会：  
- 做多路检索（锚点 + 多轮语义 + 线程）；  
- 至少经过一次 Grader；  
- 若 Grader 认为「不够」，还会触发 Explorer 再检索、再评估。  

也就是说，**没有**为「事实查证」提供「只做一次精准检索就收手」的轻量路径。

### 2.4 生成阶段：统一输出 4～6 个叙事阶段

- 最后统一进入 **Generator**（或 Q4 segment_narrative）：  
  用当前收集到的所有候选节点（可能很多），让 LLM 生成 **4～6 个叙事阶段**，每个阶段包含 phase_title、time_range、core_conclusion、evidence_msg_ids、reasoning_chain、uncertainty_note 等。
- 再经过 **reflect_on_evidence** 等步骤，最终通过 **format_cards** 输出多张「叙事卡片」。

也就是说：  
- **事实类问题**（如「去年 7 月吃了什么」）在我们系统里也会被答成「多阶段叙事」形式，而不是「一段直接事实回答 + 少量证据引用」。  
- 从产品形态上，我们也没有区分「叙事型回答」和「事实型回答」。

### 2.5 小结：当前做法的本质

- **检索**：对每个问题都做「多路召回（锚点 + 多 query 语义 + 线程）」，且对 arc_narrative 主动拉取整段时间线（最多 60 节点）。  
- **控制流**：所有问题都经历「检索 → 充足性评估 → 可能多轮探索 → 再评估」，没有按问题类型提前分流。  
- **输出**：统一是多阶段叙事卡片，没有「只答事实 + 证据」的轻量输出。  

可以概括为：**我们默认按「要覆盖整段长对话」的方式去处理每一个问题**，在此基础上仅通过 query_type 在检索侧做了一定区分（是否拉全量节点），但**没有**在控制流和输出形态上区分「叙事」与「事实查证」。

---

## 3. 这个解决方法会存在什么样的问题

下面从成本、延迟、体验和可扩展性四方面说明当前做法带来的问题。

### 3.1 成本与延迟

- **LLM 调用多**  
  每个问题至少：Q1 意图解析、Planner 生成检索 query（若走 Agent）、Retriever 多路检索后的汇总、Grader 一次或多次、Generator 一次大 prompt（节点摘要 + 生成 4～6 阶段）、以及 reflect_on_evidence。  
  对「去年 7 月我们吃了什么」这类事实问题，**本可以**：语义检索 1 次 + 时间过滤（若有）+ 1 次「根据下列片段回答问题」的 LLM 调用。

- **检索与工具调用多**  
  多 query 语义检索（每个 query 一次 ChromaDB）、每个锚点的 get_thread_neighbors、arc_narrative 的 get_all_nodes_overview；Grader 判不足时还有 Explorer 的 list_nodes_by_time / search_semantic 等。  
  对事实类问题，理想情况是：**少量、精准**的检索（例如 1 次语义 + 可选 1 次按时间过滤），无需线程扩展、无需全量概览、无需多轮探索。

- **结果**  
  事实类问题与叙事类问题在**成本与延迟**上几乎一视同仁，没有「简单问题简单算」的路径，不利于规模化或高并发场景。

### 3.2 体验与答案形态

- **事实类问题被「叙事化」**  
  用户问「去年 7 月我们吃了什么」，更自然的期待是：**一句或几句直接回答 + 可点的证据来源**。  
  当前我们统一输出 4～6 个叙事阶段，对这类问题会显得冗长、结构过重，且可能把「吃饭」拆成多个阶段，反而干扰快速获取事实。

- **探索循环对事实类价值有限**  
  Grader 的「时间象限是否全覆盖」是为「叙事弧」设计的；对「某月吃了什么」，用户更关心「有没有覆盖到 7 月」而非「Q1～Q4 是否都有节点」。  
  多轮 Explorer 补全时间线，对事实类问题容易变成**无效的加量检索**，拉高延迟却对答案质量帮助不大。

### 3.3 语义与检索逻辑

- **锚点与线程是为「叙事/异常」设计的**  
  异常锚点（回复延迟、冲突强度等）和语义线程（Layer 2）更适合：关系演变、情绪转折、话题延续等**过程型**需求。  
  对「去年 7 月吃了什么」「约了哪家店」这类**事实型**需求，锚点和线程未必能带来更好召回，反而可能引入无关节点，或分散检索注意力。

- **事实类更接近「传统 RAG」**  
  即：用问题（+ 可选时间范围）做**一次或少数几次**语义/时间过滤，得到 top-k 片段，再让 LLM 基于这些片段做**单轮问答**。  
  当前我们**没有**提供这条「传统 RAG」路径，所有问题都先进「多路召回 + 充足性评估 + 多轮探索 + 多阶段叙事」的管道。

### 3.4 可扩展性与维护

- **所有逻辑绑在一条管道上**  
  若未来要针对「事实查证」做优化（例如：更细的时间解析、只检索消息级 chunk、或接入其他检索源），需要在现有 Retriever–Grader–Explorer–Generator 里不断加分支，容易让单一路径变得复杂、难测。

- **没有显式的「问题类型 → 策略」路由**  
  意图里虽有 query_type，但**没有**据此选择「走完整叙事管道」还是「走轻量 RAG 管道」。  
  调研和后续改造的一个明确目标，就是：**根据问题类型做显式路由，让事实类走轻量、可独立优化的路径**。

---

## 4. 总结：希望调研回答什么

- **背景**：系统要同时支持「整段对话的叙事/过程」和「具体事实的查证」两类问题，且对话长、节点多，不能对所有问题都做「遍历整段对话」式的重检索。  
- **现状**：我们目前用**同一套重管道**处理所有问题——多路检索、充足性评估、多轮探索、统一生成 4～6 阶段叙事；仅在检索阶段对 arc_narrative 做了「拉满时间线」的区分。  
- **问题**：对事实类问题，这套做法导致成本高、延迟大、答案形态不匹配（叙事过重），且没有利用「传统 RAG」式的轻量路径。  

希望调研能在此基础上，厘清：

1. **两类问题**（叙事 vs 事实查证）在业界或文献中通常如何区分、用什么指标或规则可操作地分类（包括是否要新增 query_type 或单独的特征）。  
2. **事实类**在「检索策略、检索粒度、调用次数、输出形态」上，更适合的范式（例如：纯语义 top-k、时间过滤 + 语义、是否需要锚点/线程等）。  
3. **叙事类**现有「多路召回 + Grader + Explorer + 多阶段生成」哪些部分应保留、哪些可简化，以及是否要和事实类共用同一意图模型、如何分流。  
4. **路由与落地的具体形态**：在现有 Q1/Workflow 上如何加一层「问题类型 → 管道选择」（例如 factual_rag vs full_narrative），以及 API/输出格式如何同时支持「叙事卡片」和「事实回答 + 证据」两种形态。

以上内容可作为调研任务书或技术方案讨论的输入，便于其他人据此展开调研与设计。
